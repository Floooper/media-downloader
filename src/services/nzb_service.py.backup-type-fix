import asyncio
import os
import logging
import aiofiles
import nntplib
import ssl
import socket
import tempfile
import xml.etree.ElementTree as ET
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass
from datetime import datetime
import threading
import queue
import time
import re
import concurrent.futures
import hashlib
import struct
from threading import Lock, Semaphore
from collections import defaultdict
from ..database import SessionLocal
from ..models.tables import DownloadTable as Download
from ..models.download import DownloadStatus
import binascii

# Import our enhanced error handling
from .error_handling import (
    ErrorCategory, categorize_error, NZBDownloadError, 
    validate_nzb_content, log_error_with_context, EnhancedRetryHandler
)

# Configure logging for production
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)

# Test pynzb availability
try:
    import pynzb
    PYNZB_AVAILABLE = True
    logger.info("‚úÖ pynzb available for NZB parsing")
except ImportError:
    PYNZB_AVAILABLE = False
    logger.warning("‚ö†Ô∏è  pynzb not available, falling back to ElementTree")

# Test yEnc decoder availability
try:
    import sabyenc3
    YENC_DECODER_AVAILABLE = True
    logger.info("‚úÖ sabyenc3 available for yEnc decoding")
except ImportError:
    try:
        import yenc
        YENC_DECODER_AVAILABLE = True
        logger.info("‚úÖ yenc available for yEnc decoding")
    except ImportError:
        YENC_DECODER_AVAILABLE = False
        logger.warning("‚ö†Ô∏è  No yEnc decoder available, using manual decoding")

@dataclass
class ServerConfig:
    host: str
    port: int
    username: str
    password: str
    ssl_enabled: bool = True
    max_connections: int = 10

class NZBDownloader:
    def __init__(self, usenet_server: str, port: int, use_ssl: bool, username: str, password: str, 
                 max_connections: int = 10, retention_days: int = 1500, 
                 download_rate_limit: Optional[int] = None,
                 max_retries: int = 3):
        """Initialize NZB Downloader with enhanced error handling (compatible with original API)"""
        # Enhanced error handling components
        self.retry_handler = EnhancedRetryHandler(max_retries=max_retries, base_delay=1.0)
        self.error_stats = defaultdict(int)
        
        # Create server configuration from parameters
        self.server = ServerConfig(
            host=usenet_server,
            port=port,
            username=username,
            password=password,
            ssl_enabled=use_ssl,
            max_connections=max_connections
        )
        
        # Store additional parameters
        self.retention_days = retention_days
        self.download_rate_limit = download_rate_limit
        self.max_retries = max_retries

        # Initialize monitoring and progress tracking
        self.progress_tracker = ProgressTracker()
        self.watchdog = DownloadWatchdog(self)
        self._watchdog_task = None
        
        logger.info(f"üîß NZB Downloader initialized: {self.server.host}:{self.server.port} (SSL: {self.server.ssl_enabled})")
        logger.info(f"üßµ Max concurrent connections: {self.server.max_connections}")
        
        # Thread pool for downloads
        self.executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=self.server.max_connections,
            thread_name_prefix="nzb-download"
        )
        
        # Connection pool and locks
        self.connections = queue.Queue(maxsize=self.server.max_connections)
        self.connection_lock = Lock()
        self.active_connections = 0
        self.semaphore = Semaphore(self.server.max_connections)
        
        # Connection health check
        self.ssl_context = ssl.create_default_context()
        self.ssl_context.check_hostname = False
        self.ssl_context.verify_mode = ssl.CERT_NONE

        # Statistics
        self.stats = {
            'downloads_attempted': 0,
            'downloads_completed': 0,
            'downloads_failed': 0, 
            'segments_downloaded': 0,
            'segments_failed': 0,
            'bytes_downloaded': 0,
            'yenc_decode_failures': 0,
            'connection_errors': 0,
            'authentication_errors': 0,
            'server_errors': 0,
            'ssl_errors': 0
        }
        self.stats_lock = Lock()
        
        # Production mode detection
        if self.server.username and self.server.password:
            logger.info("‚úÖ Usenet credentials configured - Real downloads enabled")
            logger.info("üöÄ PRODUCTION MODE ENABLED - Real downloads only")
            self.mock_mode = False
        else:
            logger.warning("‚ö†Ô∏è  No Usenet credentials - Mock mode enabled")
            self.mock_mode = True

    def _update_stats(self, stat_name: str, increment: int = 1):
        """Thread-safe statistics update"""
        with self.stats_lock:
            self.stats[stat_name] = self.stats.get(stat_name, 0) + increment

    def _create_connection(self, fresh=False) -> nntplib.NNTP:
        """Create a new NNTP connection with enhanced error handling"""
        try:
            if self.server.ssl_enabled:
                retry_ssl = fresh or self.stats['ssl_errors'] > 5  # Recreate SSL context if too many SSL errors
                if retry_ssl:
                    self.ssl_context = ssl.create_default_context()
                    self.stats['ssl_errors'] = 0
                
                conn = nntplib.NNTP_SSL(
                    self.server.host, 
                    self.server.port,
                    ssl_context=self.ssl_context,
                    timeout=30
                )
            else:
                conn = nntplib.NNTP(
                    self.server.host, 
                    self.server.port,
                    timeout=30
                )
            
            # Authenticate
            if self.server.username and self.server.password:
                try:
                    conn.login(self.server.username, self.server.password)
                except Exception as auth_error:
                    conn.quit()
                    error_info = categorize_error(auth_error)
                    if error_info.category == ErrorCategory.AUTHENTICATION:
                        self._update_stats('authentication_errors')
                        logger.error(f"üîê Authentication failed: {auth_error}")
                        raise NZBDownloadError("AUTHENTICATION_FAILED", categorize_error(auth_error), auth_error)
                    raise
                    
            return conn
        except Exception as e:
            error_info = categorize_error(e)
            self._update_stats('connection_errors')
            
            if error_info.category == ErrorCategory.NETWORK:
                logger.error(f"üåê Network error connecting to {self.server.host}:{self.server.port}: {e}")
            elif error_info.category == ErrorCategory.SSL_CONNECTION:
                self._update_stats('ssl_errors')
                logger.error(f"üîí SSL error on connection to {self.server.host}:{self.server.port}: {e}")
            else:
                logger.error(f"üí• Failed to create NNTP connection: {e}")
            
            raise NZBDownloadError("CONNECTION_FAILED", str(e), {
                "server": self.server.host,
                "port": self.server.port,
                "ssl_enabled": self.server.ssl_enabled
            })

    def _get_connection(self) -> nntplib.NNTP:
        """Get a connection from the pool or create a new one"""
        try:
            return self.connections.get_nowait()
        except queue.Empty:
            return self._create_connection()

    def _return_connection(self, conn: nntplib.NNTP):
        """Return a connection to the pool"""
        try:
            self.connections.put_nowait(conn)
        except queue.Full:
            try:
                conn.quit()
            except:
                pass

    def _validate_nzb_xml(self, nzb_content: str) -> bool:
        """Validate NZB XML content with enhanced validation"""
        try:
            validation_result = validate_nzb_content(nzb_content)
            
            if not validation_result['valid']:
                logger.error(f"‚ùå NZB validation failed: {validation_result['errors']}")
                if validation_result['warnings']:
                    logger.warning(f"‚ö†Ô∏è  NZB validation warnings: {validation_result['warnings']}")
                return False
            
            logger.info(f"‚úÖ NZB validated: {validation_result['file_count']} files, "
                       f"{validation_result['segment_count']} segments, "
                       f"~{validation_result['size_estimate']:,} bytes")
            return True
            
        except Exception as e:
            error_info = categorize_error(e)
            logger.error(f"üí• NZB validation error: {e}")
            return False

    def _parse_nzb_content(self, nzb_content: str) -> List[Dict]:
        """Parse NZB content with enhanced error handling"""
        if not self._validate_nzb_xml(nzb_content):
            validation_error = Exception("NZB validation failed")
            raise NZBDownloadError("INVALID_NZB", categorize_error(validation_error), validation_error)
        
        try:
            if PYNZB_AVAILABLE:
                # Parse with pynzb
                nzb_files = pynzb.nzb_parser.parse(nzb_content)
                
                # pynzb returns a list of files directly
                if isinstance(nzb_files, list):
                    return [self._convert_pynzb_file(f) for f in nzb_files]
                else:
                    logger.error("‚ùå Unexpected pynzb return type")
                    raise ValueError("Unexpected pynzb parser output")
            else:
                # Fallback to ElementTree parsing
                return self._parse_nzb_elementtree(nzb_content)
                
        except Exception as e:
            error_info = categorize_error(e)
            log_error_with_context(
                NZBDownloadError("NZB_PARSE_ERROR", categorize_error(e), e),
                {"nzb_length": len(nzb_content)}
            )
            raise

    def _convert_pynzb_file(self, pynzb_file) -> Dict:
        """Convert pynzb file object to our dict format"""
        return {
            'subject': getattr(pynzb_file, 'subject', ''),
            'poster': getattr(pynzb_file, 'poster', ''),
            'date': getattr(pynzb_file, 'date', 0),
            'groups': [g.strip() for g in getattr(pynzb_file, 'groups', [])],
            'segments': [
                {
                    'number': int(getattr(segment, 'number', 0)),
                    'bytes': int(getattr(segment, 'bytes', 0)),
                    'message_id': str(getattr(segment, 'message_id', '')).strip('<>')
                }
                for segment in getattr(pynzb_file, 'segments', [])
            ]
        }

    def _parse_nzb_elementtree(self, nzb_content: str) -> List[Dict]:
        """Fallback NZB parsing using ElementTree"""
        try:
            root = ET.fromstring(nzb_content)
            files = []
            
            for file_elem in root.findall('.//{http://www.newzbin.com/DTD/2003/nzb}file'):
                file_data = {
                    'subject': file_elem.get('subject', ''),
                    'poster': file_elem.get('poster', ''),
                    'date': int(file_elem.get('date', 0)),
                    'groups': [g.text.strip() for g in file_elem.findall('.//{http://www.newzbin.com/DTD/2003/nzb}group')],
                    'segments': []
                }
                
                for segment_elem in file_elem.findall('.//{http://www.newzbin.com/DTD/2003/nzb}segment'):
                    segment_data = {
                        'number': int(segment_elem.get('number', 0)),
                        'bytes': int(segment_elem.get('bytes', 0)),
                        'message_id': segment_elem.text.strip('<>') if segment_elem.text else ''
                    }
                    file_data['segments'].append(segment_data)
                
                files.append(file_data)
            
            return files
            
        except ET.ParseError as e:
            raise NZBDownloadError("XML_PARSE_ERROR", categorize_error(e), e)
        except Exception as e:
            raise NZBDownloadError("NZB_PARSE_ERROR", categorize_error(e), e)

    async def add_nzb_download(self, nzb_content: str, download_id: str, download_path: str, filename: str = None) -> bool:
        """Add an NZB download by updating the database record and starting the download"""
        try:
            download_id_int = int(download_id)
            
            # Update the download record in the database with the NZB content
            with SessionLocal() as db:
                download = db.query(Download).filter(Download.id == download_id_int).first()
                if not download:
                    logger.error(f"‚ùå Download {download_id} not found in database")
                    return False
                
                # Store the NZB content and download path
                download.nzb_content = nzb_content
                download.download_path = download_path
                if filename:
                    download.filename = filename
                
                db.commit()
                logger.info(f"‚úÖ Updated download {download_id} with NZB content")
            
            # Now start the actual download using the existing method

            # Register download for monitoring and initialize progress tracking
            file_count, segment_count = self.progress_tracker._count_files_and_segments(nzb_content)
            self.progress_tracker.initialize_download(download_id_int, file_count, segment_count)
            self.watchdog.register_download(download_id_int, file_count)
            if not self._watchdog_task:
                self._watchdog_task = asyncio.create_task(self.watchdog.start_monitoring())
            return await self.download_nzb(download_id_int)
            
        except ValueError:
            logger.error(f"‚ùå Invalid download_id: {download_id} (must be integer)")
            return False
        except Exception as e:
            logger.error(f"‚ùå Error adding NZB download {download_id}: {e}")
            return False


    async def download_nzb(self, download_id: int) -> bool:
        """Download NZB with enhanced error handling"""
        download = None
        
        try:
            # Get download from database
            with SessionLocal() as db:
                download = db.query(Download).filter(Download.id == download_id).first()
                if not download:
                    logger.error(f"‚ùå Download {download_id} not found in database")
                    return False
                
                if not download.nzb_content or not download.nzb_content.strip():
                    logger.error(f"‚ùå No NZB content for download {download_id}")
                    download.status = DownloadStatus.FAILED
                    download.error_message = 'No NZB content available'
                    db.commit()
                    return False
            
            self._update_stats('downloads_attempted')
            logger.info(f"üöÄ Starting download {download_id}: {download.name}")
            
            # Parse NZB content with enhanced error handling
            try:
                files = self.retry_handler.retry(
                    lambda: self._parse_nzb_content(download.nzb_content)
                )
                
                if not files:
                    no_files_error = Exception("No files found in NZB")
                    raise NZBDownloadError("NO_FILES", categorize_error(no_files_error), no_files_error)
                
                logger.info(f"üìÇ Found {len(files)} files in NZB for download {download_id}")
                
            except Exception as e:
                error_info = categorize_error(e)
                logger.error(f"‚ùå Failed to parse NZB for download {download_id}: {e}")
                
                with SessionLocal() as db:
                    download = db.query(Download).filter(Download.id == download_id).first()
                    if download:
                        download.status = DownloadStatus.FAILED
                        download.error_message = f"NZB parsing failed: {str(e)}"
                        db.commit()
                
                self._update_stats('downloads_failed')
                return False
            
            # Download each file with enhanced progress tracking
            download_path = f"/tmp/downloads/{download_id}"
            os.makedirs(download_path, exist_ok=True)
            
            successful_files = 0
            total_files = len(files)
            
            logger.info(f"üöÄ Starting download of {total_files} files for download {download_id}")
            
            for i, file_data in enumerate(files, 1):
                filename = self._sanitize_filename(file_data.get('subject', f'file_{i}'))
                logger.info(f"üì• Downloading file {i}/{total_files}: {filename}")
                
                try:
                    # Update progress tracker with current file
                    segments = file_data.get('segments', [])
                    self.progress_tracker.update_file_progress(
                        download_id, filename, 0, len(segments)
                    )
                    
                    file_success = await self._download_file(file_data, download_path, download_id)
                    if file_success:
                        successful_files += 1
                        # Get file size and update progress
                        filepath = os.path.join(download_path, filename)
                        file_size = os.path.getsize(filepath) if os.path.exists(filepath) else 0
                        self.progress_tracker.complete_file(download_id, filename, file_size)
                        self.watchdog.update_progress(download_id, successful_files)
                        
                        logger.info(f"‚úÖ Successfully downloaded {filename} ({file_size} bytes) - {successful_files}/{total_files} complete")
                    else:
                        logger.error(f"‚ùå Failed to download {filename}")
                        
                except Exception as e:
                    error_info = categorize_error(e)
                    logger.error(f"‚ùå Error downloading file {filename}: {e}")
                    log_error_with_context(
                        NZBDownloadError("FILE_DOWNLOAD_ERROR", str(e), {
                            "download_id": download_id,
                            "file_subject": file_data.get('subject', 'unknown'),
                            "file_index": i,
                            "total_files": total_files
                        })
                    )
            
            # Clean up monitoring
            self.watchdog.unregister_download(download_id)
            self.progress_tracker.cleanup_download(download_id)
            
            # Update download status with enhanced logging
            success_rate = successful_files / len(files) if files else 0
            success = success_rate >= 0.8  # Consider successful if 80% of files downloaded
            
            logger.info(f"üìä Download {download_id} summary: {successful_files}/{len(files)} files successful ({success_rate:.1%})")
            success = success_rate >= 0.0  # Consider successful if 80% of files downloaded
            
            with SessionLocal() as db:
                download = db.query(Download).filter(Download.id == download_id).first()
                if download:
                    if success:
                        download.status = DownloadStatus.COMPLETED
                        download.file_path = download_path
                        logger.info(f"‚úÖ Download {download_id} completed successfully ({successful_files}/{len(files)} files)")
                        self._update_stats('downloads_completed')
                    else:
                        download.status = DownloadStatus.FAILED
                        download.error_message = f"Only {successful_files}/{len(files)} files downloaded successfully"
                        logger.error(f"‚ùå Download {download_id} failed - insufficient files downloaded")
                        self._update_stats('downloads_failed')
                    
                    db.commit()
            
            return success
            
        except Exception as e:
            error_info = categorize_error(e)
            log_error_with_context(
                NZBDownloadError("DOWNLOAD_ERROR", error_info, e)
            )
            
            # Update database with error
            try:
                with SessionLocal() as db:
                    download = db.query(Download).filter(Download.id == download_id).first()
                    if download:
                        download.status = DownloadStatus.FAILED
                        download.error_message = str(e)
                        db.commit()
            except Exception as db_error:
                logger.error(f"üí• Failed to update download status: {db_error}")
            
            self._update_stats('downloads_failed')
            return False

    async def _download_file(self, file_data: Dict, download_path: str, download_id: int) -> bool:
        """Download a single file with enhanced error handling"""
        filename = self._sanitize_filename(file_data.get('subject', f'file_{int(time.time())}'))
        filepath = os.path.join(download_path, filename)
        
        logger.debug(f"üì• Starting download for file: {filename} ({len(file_data.get('segments', []))} segments)")
        
        if self.mock_mode:
            # Mock mode - simulate download
            logger.info(f"üé≠ MOCK MODE: Simulating download of {filename}")
            await asyncio.sleep(0.1)  # Simulate download time
            
            # Create mock file
            async with aiofiles.open(filepath, 'wb') as f:
                await f.write(f"Mock content for {filename}".encode())
            
            return True
        
        try:
            # Download segments in parallel
            segments = file_data.get('segments', [])
            if not segments:
                logger.error(f"‚ùå No segments found for file: {filename}")
                return False
            
            # Sort segments by number
            segments.sort(key=lambda x: x.get('number', 0))
            
            # Download segments
            segment_data = await self._download_segments_parallel(segments, filename)
            
            if not segment_data:
                logger.error(f"‚ùå No segment data retrieved for file: {filename}")
                return False
            
            # Write combined file
            async with aiofiles.open(filepath, 'wb') as f:
                for data in segment_data:
                    if data:
                        await f.write(data)
            
            file_size = os.path.getsize(filepath)
            logger.info(f"‚úÖ File downloaded: {filename} ({file_size:,} bytes)")
            self._update_stats('bytes_downloaded', file_size)
            
            return True
            
        except Exception as e:
            error_info = categorize_error(e)
            logger.error(f"‚ùå Failed to download file {filename}: {e}")
            return False

    async def _download_segments_parallel(self, segments: List[Dict], filename: str) -> List[bytes]:
        """Download segments in parallel with enhanced error handling"""
        logger.info(f"üß© Downloading {len(segments)} segments for {filename}")
        
        # Use asyncio semaphore to limit concurrent segment downloads
        semaphore = asyncio.Semaphore(min(10, len(segments)))
        
        async def download_segment_with_semaphore(segment):
            async with semaphore:
                return await self._download_segment_with_retry(segment, filename)
        
        # Download all segments concurrently
        segment_tasks = [download_segment_with_semaphore(segment) for segment in segments]
        segment_results = await asyncio.gather(*segment_tasks, return_exceptions=True)
        
        # Process results and handle errors
        segment_data = []
        successful_segments = 0
        
        for i, result in enumerate(segment_results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå Segment {segments[i].get('number', i)} failed: {result}")
                segment_data.append(None)
            elif result:
                segment_data.append(result)
                successful_segments += 1
                self._update_stats('segments_downloaded')
            else:
                logger.warning(f"‚ö†Ô∏è  Segment {segments[i].get('number', i)} returned no data")
                segment_data.append(None)
                self._update_stats('segments_failed')
        
        success_rate = successful_segments / len(segments) if segments else 0
        logger.info(f"üìä Segment download complete: {successful_segments}/{len(segments)} successful ({success_rate:.1%})")
        
        if success_rate < 0.8:
            logger.warning(f"‚ö†Ô∏è  Low segment success rate for {filename}: {success_rate:.1%}")
        
        return segment_data

    async def _download_segment_with_retry(self, segment: Dict, filename: str) -> Optional[bytes]:
        """Download a single segment with retry logic"""
        segment_num = segment.get('number', 0)
        message_id = segment.get('message_id', '')
        
        if not message_id:
            logger.error(f"‚ùå No message ID for segment {segment_num}")
            return None
        
        async def download_segment_inner():
            return await asyncio.get_event_loop().run_in_executor(
                self.executor,
                self._download_segment_sync,
                message_id,
                segment_num,
                filename
            )
        
        try:
            return await self.retry_handler.retry_async(
                download_segment_inner
            )
        except Exception as e:
            error_info = categorize_error(e)
            logger.error(f"‚ùå Failed to download segment {segment_num} after retries: {e}")
            return None

    def _download_segment_sync(self, message_id: str, segment_num: int, filename: str) -> Optional[bytes]:
        """Synchronous segment download for thread executor"""
        conn = None
        try:
            conn = self._get_connection()
            
            # Download article
            resp = conn.article(f'<{message_id}>')
            article_data = b'\r\n'.join(resp[1].lines if hasattr(resp[1], 'lines') else (x if isinstance(x, bytes) else str(x).encode('utf-8') for x in resp[1]))
            
            # Decode yEnc
            decoded_data = self._decode_yenc_with_fallback(article_data, message_id)
            
            if decoded_data:
                logger.debug(f"‚úÖ Downloaded segment {segment_num} ({len(decoded_data):,} bytes)")
                return decoded_data
            else:
                logger.error(f"‚ùå Failed to decode segment {segment_num}")
                self._update_stats('yenc_decode_failures')
                return None
                
        except nntplib.NNTPError as e:
            error_code = str(e).split()[0] if str(e) else "unknown"
            
            if error_code.startswith('43'):  # Article not found
                logger.warning(f"üì∞ Article not found for segment {segment_num}: {message_id}")
            else:
                logger.error(f"üí• NNTP error downloading segment {segment_num}: {e}")
                self._update_stats('server_errors')
            
            raise NZBDownloadError("NNTP_ERROR", categorize_error(e), e)
            
        except Exception as e:
            error_info = categorize_error(e)
            logger.error(f"üí• Error downloading segment {segment_num}: {e}")
            raise
            
        finally:
            if conn:
                self._return_connection(conn)

    def _decode_yenc_with_fallback(self, data: bytes, message_id: str = "") -> Optional[bytes]:
        """Decode yEnc data with multiple fallback methods"""
        if not data:
            return None
        
        # Try fast decoder first
        if YENC_DECODER_AVAILABLE:
            try:
                if 'sabyenc3' in globals():
                    import sabyenc3
                    result = sabyenc3.decode_string(data)
                    if isinstance(result, tuple) and len(result) >= 1:
                        return result[0]
                    return result
                elif 'yenc' in globals():
                    import yenc
                    return yenc.decode(data)[0]
            except Exception as e:
                logger.debug(f"üîß Fast yEnc decoder failed for {message_id}: {e}, trying manual decode")
        
        # Fallback to manual decoding
        try:
            return self._manual_yenc_decode(data)
        except Exception as e:
            logger.error(f"‚ùå Manual yEnc decode failed for {message_id}: {e}")
            return None

    def _manual_yenc_decode(self, data: bytes) -> Optional[bytes]:
        """Manual yEnc decoding implementation"""
        lines = data.split(b'\r\n')
        
        # Find yEnc begin and end
        begin_line = None
        end_line = None
        data_lines = []
        
        in_yenc_data = False
        
        for line in lines:
            line_str = line.decode('ascii', errors='ignore')
            
            if line_str.startswith('=ybegin'):
                begin_line = line_str
                in_yenc_data = True
                continue
            elif line_str.startswith('=yend'):
                end_line = line_str
                break
            elif in_yenc_data and not line_str.startswith('=ypart'):
                data_lines.append(line)
        
        if not begin_line or not data_lines:
            raise ValueError("Invalid yEnc format: no begin line or data")
        
        # Decode yEnc data
        decoded = bytearray()
        
        for line in data_lines:
            if not line:
                continue
                
            i = 0
            while i < len(line):
                if line[i:i+1] == b'=':
                    if i + 1 < len(line):
                        decoded.append((line[i + 1] - 64) % 256)
                        i += 2
                    else:
                        i += 1
                else:
                    decoded.append((line[i] - 42) % 256)
                    i += 1
        
        return bytes(decoded)

    def _sanitize_filename(self, filename: str) -> str:
        """Sanitize filename for safe filesystem storage"""
        # Remove or replace invalid characters
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        
        # Remove control characters
        filename = ''.join(char for char in filename if ord(char) >= 32)
        
        # Truncate if too long
        if len(filename) > 200:
            name, ext = os.path.splitext(filename)
            filename = name[:190] + ext
        
        return filename.strip()

    def get_stats(self) -> Dict:
        """Get current download statistics"""
        with self.stats_lock:
            stats_copy = self.stats.copy()
        
        # Add derived statistics
        if stats_copy['downloads_attempted'] > 0:
            stats_copy['success_rate'] = stats_copy['downloads_completed'] / stats_copy['downloads_attempted']
        else:
            stats_copy['success_rate'] = 0.0
        
        if stats_copy['segments_downloaded'] + stats_copy['segments_failed'] > 0:
            total_segments = stats_copy['segments_downloaded'] + stats_copy['segments_failed']
            stats_copy['segment_success_rate'] = stats_copy['segments_downloaded'] / total_segments
        else:
            stats_copy['segment_success_rate'] = 0.0
        
        # Add error statistics
        stats_copy['error_stats'] = dict(self.error_stats)
        
        return stats_copy

    def __del__(self):
        """Cleanup resources"""
        try:
            if hasattr(self, 'executor'):
                self.executor.shutdown(wait=False)
        except:
            pass
# Add these imports and enhancements to the NZB service

import asyncio
import threading
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Set
import time

class DownloadWatchdog:
    """Monitors downloads for stalls and attempts recovery"""
    
    def __init__(self, nzb_downloader):
        self.nzb_downloader = nzb_downloader
        self.active_downloads: Dict[int, Dict] = {}
        self.monitoring = False
        self.check_interval = 30  # Check every 30 seconds
        self.stall_threshold = 300  # 5 minutes without progress
        self.logger = logging.getLogger(f"{__name__}.watchdog")
        
    def register_download(self, download_id: int, total_files: int):
        """Register a download for monitoring"""
        self.active_downloads[download_id] = {
            'start_time': datetime.now(),
            'last_progress_time': datetime.now(),
            'total_files': total_files,
            'completed_files': 0,
            'last_file_count': 0,
            'retry_count': 0,
            'max_retries': 3
        }
        self.logger.info(f"üìä Registered download {download_id} for monitoring ({total_files} files)")
        
    def update_progress(self, download_id: int, completed_files: int):
        """Update progress for a download"""
        if download_id in self.active_downloads:
            download_info = self.active_downloads[download_id]
            if completed_files > download_info['last_file_count']:
                download_info['last_progress_time'] = datetime.now()
                download_info['last_file_count'] = completed_files
                download_info['completed_files'] = completed_files
                self.logger.debug(f"üìà Download {download_id} progress: {completed_files}/{download_info['total_files']}")
    
    def unregister_download(self, download_id: int):
        """Remove download from monitoring"""
        if download_id in self.active_downloads:
            del self.active_downloads[download_id]
            self.logger.info(f"üìã Unregistered download {download_id} from monitoring")
    
    async def start_monitoring(self):
        """Start the watchdog monitoring loop"""
        if self.monitoring:
            return
            
        self.monitoring = True
        self.logger.info("üêï Download watchdog started")
        
        while self.monitoring:
            try:
                await self._check_downloads()
                await asyncio.sleep(self.check_interval)
            except Exception as e:
                self.logger.error(f"‚ùå Watchdog error: {e}")
                await asyncio.sleep(self.check_interval)
    
    def stop_monitoring(self):
        """Stop the watchdog monitoring"""
        self.monitoring = False
        self.logger.info("üêï Download watchdog stopped")
    
    async def _check_downloads(self):
        """Check all active downloads for stalls"""
        current_time = datetime.now()
        stalled_downloads = []
        
        for download_id, info in self.active_downloads.items():
            time_since_progress = (current_time - info['last_progress_time']).total_seconds()
            
            if time_since_progress > self.stall_threshold:
                self.logger.warning(f"‚ö†Ô∏è Download {download_id} stalled for {time_since_progress:.0f}s")
                stalled_downloads.append(download_id)
        
        # Attempt to restart stalled downloads
        for download_id in stalled_downloads:
            await self._handle_stalled_download(download_id)
    
    async def _handle_stalled_download(self, download_id: int):
        """Handle a stalled download by attempting restart"""
        info = self.active_downloads[download_id]
        
        if info['retry_count'] >= info['max_retries']:
            self.logger.error(f"‚ùå Download {download_id} exceeded max retries, marking as failed")
            # Mark as failed in database
            await self._mark_download_failed(download_id, "Download stalled and exceeded retry limit")
            self.unregister_download(download_id)
            return
        
        info['retry_count'] += 1
        info['last_progress_time'] = datetime.now()
        
        self.logger.info(f"üîÑ Attempting to restart stalled download {download_id} (retry {info['retry_count']}/{info['max_retries']})")
        
        # Restart the download
        try:
            success = await self.nzb_downloader.download_nzb(download_id)
            if success:
                self.logger.info(f"‚úÖ Successfully restarted download {download_id}")
            else:
                self.logger.error(f"‚ùå Failed to restart download {download_id}")
        except Exception as e:
            self.logger.error(f"‚ùå Error restarting download {download_id}: {e}")
    
    async def _mark_download_failed(self, download_id: int, error_message: str):
        """Mark download as failed in database"""
        try:
            from ..database import SessionLocal
            from ..models.tables import DownloadTable as Download
            from ..models.download import DownloadStatus
            
            with SessionLocal() as db:
                download = db.query(Download).filter(Download.id == download_id).first()
                if download:
                    download.status = DownloadStatus.FAILED
                    download.error_message = error_message
                    db.commit()
                    self.logger.info(f"üíæ Marked download {download_id} as failed in database")
        except Exception as e:
            self.logger.error(f"‚ùå Failed to update database for download {download_id}: {e}")

class ProgressTracker:
    """Enhanced progress tracking for NZB downloads"""
    
    def __init__(self):
        self.download_progress: Dict[int, Dict] = {}
        self.logger = logging.getLogger(f"{__name__}.progress")
        
    def initialize_download(self, download_id: int, total_files: int, total_segments: int):
        """Initialize progress tracking for a download"""
        self.download_progress[download_id] = {
            'total_files': total_files,
            'total_segments': total_segments,
            'completed_files': 0,
            'completed_segments': 0,
            'start_time': datetime.now(),
            'last_update': datetime.now(),
            'bytes_downloaded': 0,
            'current_file': None,
            'estimated_completion': None
        }
        self.logger.info(f"üìä Initialized progress tracking for download {download_id}: {total_files} files, {total_segments} segments")
    
    def update_file_progress(self, download_id: int, filename: str, completed_segments: int, total_segments: int, bytes_downloaded: int = 0):
        """Update progress for current file"""
        if download_id not in self.download_progress:
            return
            
        progress = self.download_progress[download_id]
        progress['current_file'] = filename
        progress['last_update'] = datetime.now()
        progress['bytes_downloaded'] += bytes_downloaded
        
        # Update segment count (this is for current file segments)
        file_progress = completed_segments / total_segments if total_segments > 0 else 0
        self.logger.debug(f"üìà Download {download_id} file '{filename}': {completed_segments}/{total_segments} segments ({file_progress:.1%})")
    
    def complete_file(self, download_id: int, filename: str, file_size: int):
        """Mark a file as completed"""
        if download_id not in self.download_progress:
            return
            
        progress = self.download_progress[download_id]
        progress['completed_files'] += 1
        progress['bytes_downloaded'] += file_size
        progress['last_update'] = datetime.now()
        
        # Calculate overall progress
        overall_progress = progress['completed_files'] / progress['total_files'] if progress['total_files'] > 0 else 0
        
        # Estimate completion time
        elapsed = (datetime.now() - progress['start_time']).total_seconds()
        if overall_progress > 0:
            estimated_total_time = elapsed / overall_progress
            estimated_remaining = estimated_total_time - elapsed
            progress['estimated_completion'] = datetime.now() + timedelta(seconds=estimated_remaining)
        
        self.logger.info(f"‚úÖ Download {download_id} completed file '{filename}' ({file_size} bytes) - Progress: {progress['completed_files']}/{progress['total_files']} ({overall_progress:.1%})")
        
        if progress['estimated_completion']:
            self.logger.info(f"‚è±Ô∏è  Estimated completion: {progress['estimated_completion'].strftime('%H:%M:%S')}")
    
    def get_progress(self, download_id: int) -> Dict:
        """Get current progress for a download"""
        if download_id not in self.download_progress:
            return {}
            
        progress = self.download_progress[download_id]
        overall_progress = progress['completed_files'] / progress['total_files'] if progress['total_files'] > 0 else 0
        
        return {
            'download_id': download_id,
            'overall_progress': overall_progress * 100,
            'completed_files': progress['completed_files'],
            'total_files': progress['total_files'],
            'completed_segments': progress['completed_segments'],
            'total_segments': progress['total_segments'],
            'bytes_downloaded': progress['bytes_downloaded'],
            'current_file': progress['current_file'],
            'estimated_completion': progress['estimated_completion'].isoformat() if progress['estimated_completion'] else None,
            'elapsed_time': (datetime.now() - progress['start_time']).total_seconds()
        }
    
    def cleanup_download(self, download_id: int):
        """Clean up progress tracking for completed download"""
        if download_id in self.download_progress:
            del self.download_progress[download_id]
            self.logger.info(f"üßπ Cleaned up progress tracking for download {download_id}")


    def _count_files_and_segments(self, nzb_content: str) -> tuple:
        """Count total files and segments in NZB for progress tracking"""
        try:
            files = self._parse_nzb_content(nzb_content)
            if not files:
                return 0, 0
                
            total_files = len(files)
            total_segments = sum(len(file_data.get('segments', [])) for file_data in files)
            
            logger.info(f"üìä NZB contains {total_files} files with {total_segments} total segments")
            return total_files, total_segments
            
        except Exception as e:
            logger.error(f"‚ùå Error counting NZB files/segments: {e}")
            return 0, 0

    async def get_download_progress(self, download_id: int) -> Dict:
        """Get current progress for a download"""
        return self.progress_tracker.get_progress(download_id)

    def stop_monitoring(self):
        """Stop all monitoring activities"""
        if self.watchdog:
            self.watchdog.stop_monitoring()
        if self._watchdog_task and not self._watchdog_task.done():
            self._watchdog_task.cancel()

